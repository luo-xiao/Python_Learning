{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tune the Model\n",
    "Given that we have got a shortlist of promising models. Now there are several ways to fine-tune:\n",
    "1. Grid Search\n",
    "2. Randomized Search\n",
    "3. Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import pickle\n",
    "train_pickle_path = 'datasets/train.pickle'\n",
    "\n",
    "with open(train_pickle_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "housing_labels = data[0]\n",
    "housing_prepared = data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV   # try the values and evaluate with cross-validation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "# 3 x 4 = 12 combinations from 1st dict\n",
    "# 2 x 3 = 6  combinations from 2nd dict\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          return_train_score=True)\n",
    "\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 8, 'n_estimators': 30}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> observing that the best values are the maximum values in the grid, should try searching again with higher values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=8, n_estimators=30)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64123.653653266585 {'max_features': 2, 'n_estimators': 3}\n",
      "55293.976835407964 {'max_features': 2, 'n_estimators': 10}\n",
      "52878.50980723279 {'max_features': 2, 'n_estimators': 30}\n",
      "59301.9935157182 {'max_features': 4, 'n_estimators': 3}\n",
      "52764.27044418638 {'max_features': 4, 'n_estimators': 10}\n",
      "50792.03891498849 {'max_features': 4, 'n_estimators': 30}\n",
      "59445.82603033464 {'max_features': 6, 'n_estimators': 3}\n",
      "52609.6146075253 {'max_features': 6, 'n_estimators': 10}\n",
      "50010.53572367903 {'max_features': 6, 'n_estimators': 30}\n",
      "59019.96772834409 {'max_features': 8, 'n_estimators': 3}\n",
      "51938.67144870794 {'max_features': 8, 'n_estimators': 10}\n",
      "49903.53226365907 {'max_features': 8, 'n_estimators': 30}\n",
      "63174.975693533255 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "54339.606052357645 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "60067.304555404684 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "52234.15507018981 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "57513.46318279268 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "51344.54494542182 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--> features that are not sure about can also be treated as hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Randomized Search\n",
    "preferable when search space is large, by trying random hyperparameters at each iteration\n",
    "#### 3. Ensemble Methods\n",
    "\"ensemble\" methods will often perform better than the best individual model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the Best Model\n",
    "- Check the importance of the attributes to decide on which features to keep\n",
    "- Check the specific errors the model is making, understand why and fix the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.91634296e-02, 6.95757669e-02, 4.37219642e-02, 1.57916331e-02,\n",
       "       1.43938346e-02, 1.45351234e-02, 1.44777900e-02, 3.57193769e-01,\n",
       "       3.96387068e-02, 1.11862204e-01, 8.23834481e-02, 6.27440862e-03,\n",
       "       1.56613554e-01, 5.81584731e-05, 1.30351637e-03, 3.01269287e-03])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pickle_path = 'datasets/test.pickle'\n",
    "\n",
    "with open(test_pickle_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "y_test = data[0]\n",
    "X_test_prepared = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47809.56699185216"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse  # an estimate of the generalization error (out-of-sample error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45836.86842477, 49704.03288373])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "confidence = 0.95\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) -1, \n",
    "                        loc=squared_errors.mean(),\n",
    "                        scale=stats.sem(squared_errors)))  # 95% confidence interval for the generalization error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch, Monitor and Maintain the System\n",
    "__Launch__: deploy the model to the production environment\\\n",
    "__Monitor__: evaluate the live model with or w/o human raters (be smart)\\\n",
    "__Maintain__: evaluate and update the data sets & retrain the model --> on a regular basis needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
